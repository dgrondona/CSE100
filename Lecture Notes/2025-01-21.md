# 2025-01-21

Went over what the course is about and some things from the syllabus.

## Multiplication

- we can describe the number of digits of the numbers we are multiplying with the letter n
- when n gets very large, it becomes harder to multiply the 2 numbers together
- multiplying using the common method of multiplication you would learn in elementary school, it would take O(n^2) to solve. So, we would need to do about n^2 operations.
    - there are more then n^2 operations due to the additions we need and number carries, but we call it O(n^2) since the large n term dominates
- our operation always scales like n^2, so even if you are doing the problem yourself or a supercomputer is doing the problem, it still scales in relation to n^2
- we can describe an algorithm that has a lower order as asymptotically faster, meaning as time approaches infinity, the algorithm would be faster

### Can we do Better than N^2?

#### Divide and Conquer

We can break a problem up into smaller and smaller problems and solve those.

Example:
```
1234 = 12 x 100 + 34

1234 x 5678
= (12 x 100 + 34)(56 x 10 + 78)
```

In this example, we turned our 4 digit multiplication into 2 2 digit multiplications.

More generally:
```
X x Y
= (a x c)10^n + (a x d + c x b)10^n/2 + (b x d)

---

mult(x,y):

if n = 1:
    return xy

write x = a 10^n/2 + b

write y = c10^n/2 + d

recursibely compute ac, ad, bc, bd:
    ac = mult(a,c), etc.

add them up to get xy:
    xy = ac10^n + (ad + bc)10^n/2 + bd
```

If we recurse on those 2-digit multiplication problems, we would end up with 16 1-digit multiplications.

Looking at a graph of our divide and conquer method, there seems to be something funny happening at powers of 2...

Trying to understand the runtime analytically, with an 8-digit number, we would get 64 1-digit multiplications. So, we could say that an n-digit multiplication would break up into n^2 1-digit multiplications.